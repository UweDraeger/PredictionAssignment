---
title: "PredictionAssignment"
author: "Uwe Draeger"
date: "3/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)

```

## Executive Summary

Lorem ipsunt ...


## Data import

```{r cars}

```

Final goal is to predict the manner in which the exercise was done in the test data set. 




## Exploration

An analysis of the out-of-sample data shows that quite a few variables consist of missing values only. It may not be sensible to even start to construct a prediction model which might finally rely on indicators which are not available when finally performing the predictions. This reasoning creates a first exclusion criterion for variables in the training data set. 

The result is a list of 59 variables available as predictors. Some of the them serve as descriptors and can reasonably be expected to have no influence on the outcome. Those will be excluded from the model building process as well. 52 variables survive. 


The training data contains information on six different users with at least 2,600 observations. 
The number of observations in each class of execution (classe) is large, with a minimum of almost 500 obervation per bucket, and relatively easily split.

```{r users}

table(pml_training$classe)
table(pml_training$user_name)
table(pml_training$user_name, pml_training$classe)

```



## Cross validation

As there is an independent test data, there is no need to set aside observations for final testing. However, it seems prudent to create a validation set to enable some estimation of expected prediction error. 

One might also consider 

## Model building

Type of final model: Classification - has the exercise been performed as specified or what type of mistake has been made.

Tuning was performed using mtry = c(6,7,8) trees = c(100, 200, 500) - almost no differences in accuracy, sens or spec = use mtry = 6 and trees = 100

        mtry trees .metric  .estimator  mean     n  std_err .config             
        <dbl> <dbl> <chr>    <chr>      <dbl> <int>    <dbl> <chr>               
 1     6   100 accuracy multiclass 0.996    10 0.000479 Preprocessor1_Model1
 2     6   100 sens     macro      0.995    10 0.000565 Preprocessor1_Model1
 3     6   100 spec     macro      0.999    10 0.000124 Preprocessor1_Model1
 
   mtry trees .metric  .estimator  mean     n  std_err .config             
  <dbl> <dbl> <chr>    <chr>      <dbl> <int>    <dbl> <chr>               
1     5    10 accuracy multiclass 0.991    10 0.00106  Preprocessor1_Model9
2     5    10 sens     macro      0.990    10 0.00121  Preprocessor1_Model9
3     5    10 spec     macro      0.998    10 0.000271 Preprocessor1_Model9
 

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
